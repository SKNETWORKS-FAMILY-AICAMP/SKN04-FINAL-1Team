from sqlalchemy import create_engine
from sqlalchemy.pool import NullPool
from langchain_community.utilities import SQLDatabase

import json
import chromadb

from langchain_openai.embeddings import OpenAIEmbeddings

def get_db_engine(user, password, host, port, database):
    """PostgreSQL DBì™€ ì—°ê²°ëœ ì—”ì§„ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    try:
        # SQLAlchemy ì—”ì§„ ìƒì„± (PostgreSQL)
        engine = create_engine(
            f"postgresql://{user}:{password}@{host}:{port}/{database}",
            poolclass=NullPool  # ì»¤ë„¥ì…˜ í’€ë§ ë¹„í™œì„±í™” (ë‹¨ì¼ ì—°ê²° ì‚¬ìš©)
        )
        return engine
    except Exception as e:
        print(f"ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return None

# PostgreSQL ì ‘ì† ì •ë³´
DB_CONFIG = {
    "user": "postgres",     # PostgreSQL ì‚¬ìš©ì ì´ë¦„
    "password": "1234", # PostgreSQL ë¹„ë°€ë²ˆí˜¸
    "host": "localhost",         # PostgreSQL ì„œë²„ ì£¼ì†Œ (Docker ì‚¬ìš© ì‹œ ì»¨í…Œì´ë„ˆ ì´ë¦„ ê°€ëŠ¥)
    "port": "5432",              # PostgreSQL í¬íŠ¸ (ê¸°ë³¸ 5432)
    "database": "real_estate"    # ì‚¬ìš©í•  ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„
}

# PostgreSQL ì—”ì§„ ìƒì„±
engine = get_db_engine(**DB_CONFIG)

# LangChain SQLDatabase ê°ì²´ ìƒì„±
db = SQLDatabase(
    engine,
    sample_rows_in_table_info=False  # ìƒ˜í”Œ í–‰ ì¡°íšŒ ë¹„í™œì„±í™”
)


# 1ï¸âƒ£ ë²¡í„° ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
model = OpenAIEmbeddings(model="text-embedding-3-small")

# 2ï¸âƒ£ ChromaDB ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
chroma_client = chromadb.PersistentClient(path="./chroma_db")  # ì˜êµ¬ ì €ì¥
collection = chroma_client.get_or_create_collection(name="jsonl_vectors")

# 3ï¸âƒ£ ì§ˆë¬¸ì„ ë„ì–´ì“°ê¸° ê¸°ì¤€ìœ¼ë¡œ ë¶„í• í•˜ì—¬ ì €ì¥í•˜ëŠ” í•¨ìˆ˜
def chunk_text(text):
    chunks = text.split()
    return chunks

# 4ï¸âƒ£ ê¸°ì¡´ ë°ì´í„° í™•ì¸ í›„, ë²¡í„°DBê°€ ì—†ì„ ê²½ìš° ë°ì´í„° ì‚½ì…
def insert_data_if_empty(jsonl_file="./data/QA.jsonl"):
    existing_count = collection.count()

    if existing_count == 0:
        print("ğŸ”¹ ë²¡í„° DBê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ë°ì´í„°ë¥¼ ì‚½ì…í•©ë‹ˆë‹¤...")

        with open(jsonl_file, "r", encoding="utf-8") as f:
            for line in f:
                data = json.loads(line)  # JSON ê°ì²´ ë³€í™˜
                question = data.get("question")  # ì§ˆë¬¸ (Query)
                sql = data.get("sql")  # SQL ë¬¸ì¥

                if question and sql:
                    # ì§ˆë¬¸ì„ ì—¬ëŸ¬ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ì €ì¥ (n-gram ë°©ì‹)
                    chunks = chunk_text(question)
                    for chunk in chunks:
                        embedding = model.embed_documents([chunk])[0]  # ì²­í¬ë¥¼ ë²¡í„°í™”
                        collection.add(
                            ids=[str(len(collection.get()["ids"]))],  # ê³ ìœ  ID ìë™ ìƒì„±
                            embeddings=[embedding],
                            metadatas=[{"question": chunk, "full_question": question, "sql": sql}]  # ì›ë³¸ ë°ì´í„° ì €ì¥
                        )

        print("âœ… ë°ì´í„° ì‚½ì… ì™„ë£Œ!")
    else:
        print(f"ğŸ”¹ ê¸°ì¡´ì— {existing_count}ê°œì˜ ë²¡í„° ë°ì´í„°ê°€ ì¡´ì¬í•©ë‹ˆë‹¤. ì‚½ì…ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
