from typing import TypedDict, Annotated, List, Dict
from langgraph.graph.message import add_messages
from langchain_core.messages import HumanMessage, SystemMessage, RemoveMessage
from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool

from utils import llm
from postgresql import db
from chroma_db import model, collection, initialize_vector_db

import json
import os
import yaml
import re

with open(os.path.abspath('./prompts.yaml'), 'r', encoding='utf-8') as file:
    prompts = yaml.safe_load(file)

class RealEstateState(TypedDict): # ê·¸ë˜í”„ì˜ ìƒíƒœë¥¼ ì •ì˜í•˜ëŠ” í´ë˜ìŠ¤
    real_estate_type: Annotated[str ,"ë¶€ë™ì‚° ìœ í˜• (ì˜ˆ: ì•„íŒŒíŠ¸, ìƒê°€)"]
    vector_results: Annotated[str, "ë²¡í„° ê²°ê³¼"]
    keywordlist: Annotated[List[Dict] ,"í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸"]
    messages: Annotated[list, add_messages]
    summary: Annotated[str, "ê¸¸ì–´ì§„ ë©”ì„¸ì§€ ìš”ì•½"]
    query_sql: Annotated[str ,"ìƒì„±ëœ SQL ì¿¼ë¦¬"]
    results: Annotated[List[Dict], "ì¿¼ë¦¬ ê²°ê³¼"]
    query_answer:Annotated[str, 'answerë‹¤ë“¬ê¸°']
    answers: Annotated[List[str], "ìµœì¢… ë‹µë³€ ê²°ê³¼"]
    clean_results: Annotated[List[Dict], "ê²°ê³¼ ì •ì œ"]
    properties: Annotated[List[Dict], "ë¶€ë™ì‚° ì •ë³´"]

def filter_node(state:RealEstateState) -> RealEstateState:
    print("[Filter Node] AIê°€ ì§ˆë¬¸ì„ ì‹ë³„ì¤‘ì…ë‹ˆë‹¤!!!!")
    system_prompt = prompts['filter_system_prompt']

    summary = state.get("summary", "")
    if summary:

        # Add summary to system message
        summary_message = f"Summary of conversation earlier: {summary}"

        # Append summary to any newer messages
        messages = summary_message + state["messages"][-1].content

    else:
        messages = state["messages"][-1].content

    response = llm.invoke([
        SystemMessage(content=system_prompt),
        HumanMessage(messages)
    ])

    real_estate_type = response.content.strip() 

    print(f"[Filter Node] AIê°€ ì§ˆë¬¸ì„ ì‹ë³„í–ˆìŠµë‹ˆë‹¤. {real_estate_type}")

    previous_message = state["messages"][-2].content if len(state["messages"]) > 1 else ""  # âœ… ì§ì „ ë©”ì‹œì§€

    # âœ… ë§Œì•½ ìµœê·¼ ì§ˆë¬¸ì´ ë¶€ë™ì‚°ê³¼ ê´€ë ¨ ì—†ìœ¼ë©´ ì§ì „ ì§ˆë¬¸ê³¼ ì—°ê²° ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
    if real_estate_type == "Fail" and previous_message:
        print("[Filter Node] ìµœê·¼ ì§ˆë¬¸ì´ ì• ë§¤í•´ì„œ ì§ì „ ì§ˆë¬¸ê³¼ ì—°ê²° ì—¬ë¶€ ê²€ì‚¬ ì¤‘...")
        
        combined_message = previous_message + " " + messages
        combined_response = llm.invoke([
            SystemMessage(content=system_prompt),
            HumanMessage(combined_message)
        ])
        
        combined_real_estate_type = combined_response.content.strip()
        print(f"[Filter Node] ì§ì „ ì§ˆë¬¸ê³¼ ê²°í•© ì‹œ: {combined_real_estate_type}")

        # âœ… ì§ì „ ì§ˆë¬¸ê³¼ í•©ì³¤ì„ ë•Œ ë¶€ë™ì‚° ê´€ë ¨ì´ë©´ ìœ ì§€
        if combined_real_estate_type != "Fail":
            real_estate_type = combined_real_estate_type 
        return {"real_estate_type" : real_estate_type, "messages":messages}

    return {"real_estate_type" : real_estate_type}

def summarize_conversation(state: RealEstateState):
    summary = state.get("summary", "")
    if summary:
        summary_prompt = (
            f"í˜„ì¬ê¹Œì§€ì˜ ëŒ€í™” ìš”ì•½: {summary}\n\n"
            "ìœ„ì˜ ìƒˆë¡œìš´ ë©”ì‹œì§€ë¥¼ ê³ ë ¤í•˜ì—¬ ìš”ì•½ì„ í™•ì¥í•˜ì„¸ìš”:"
        )
    else:
        summary_prompt = "ìœ„ì˜ ëŒ€í™”ë¥¼ ìš”ì•½í•˜ì„¸ìš”:"

    messages = state["messages"] + [HumanMessage(content=summary_prompt)]
    response = llm.invoke(messages)

    # ìµœê·¼ 2ê°œì˜ ë©”ì‹œì§€ë§Œ ë‚¨ê¸°ê³  ì´ì „ ë©”ì‹œì§€ ì‚­ì œ
    delete_messages = [RemoveMessage(id=m.id) for m in state["messages"][:-2]]
    return {"summary": response.content, "messages": delete_messages,}

def should_summarize(state: RealEstateState) :
    if len(state["messages"]) > 6:
        return "summarize_conversation"
    return "Filter Question"

def fiter_router(state: RealEstateState):
    # This is the router
    real_estate_type = state["real_estate_type"]
    if real_estate_type == "Pass":
        return "Pass"
    else:
        return 'Fail'
    
def re_questions(state: RealEstateState) -> RealEstateState:
    system_prompt = """
    ëª¨ë“  ì§ˆë¬¸ì— ëŒ€í•´ ì•„ë˜ì˜ ë¬¸êµ¬ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”:

    "âŒë¶€ë™ì‚° ê´€ë ¨ ì§ˆë¬¸ì„ ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”!ğŸ "

    # Output Format
    - í•­ìƒ ìœ„ì˜ ë©”ì‹œì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¨ì¼ ë¬¸ì¥ìœ¼ë¡œ ì‘ë‹µí•˜ì‹­ì‹œì˜¤.

    """

    user_prompt=f"""
    ì‚¬ìš©ìì˜ ì§ˆë¬¸: {state['messages'][-1].content}
    """
    response = llm.invoke([
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt)
        ])
    
    output = response.content.strip()

    return {'answers': output}

def find_similar_questions(state: RealEstateState) -> RealEstateState:
    """
    ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ë²¡í„°í™”í•˜ì—¬ ChromaDBì—ì„œ ìœ ì‚¬í•œ ì§ˆë¬¸ì„ ê²€ìƒ‰.
    threshold ê°’ë³´ë‹¤ ë†’ì€(ìœ ì‚¬í•œ) ê²°ê³¼ë§Œ ë°˜í™˜.
    """
    initialize_vector_db()  # âœ… ë²¡í„° DB ì´ˆê¸°í™”

    query = state["messages"][-1].content  # âœ… ìµœì‹  ì…ë ¥ëœ ì‚¬ìš©ì ë©”ì‹œì§€
    top_k = 5  # ê²€ìƒ‰í•  ìœ ì‚¬ ì§ˆë¬¸ ê°œìˆ˜
    threshold = 0.7  # âœ… ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ì¤€ (1ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬)

    # âœ… ì…ë ¥ëœ ì§ˆë¬¸ì„ ë²¡í„°í™”
    query_embedding = model.encode([query])[0].tolist()

    # âœ… ChromaDBì—ì„œ ìœ ì‚¬ ì§ˆë¬¸ ê²€ìƒ‰
    results = collection.query(
        query_embeddings=[query_embedding],
        n_results=top_k
    )

    # âœ… ìœ ì‚¬ë„ ë³€í™˜ ë° í•„í„°ë§ (ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ì‚¬ìš©)
    filtered_results = [
        {
            "score": 1 - score,  # âœ… ì½”ì‚¬ì¸ ê±°ë¦¬ â†’ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¡œ ë³€í™˜ (1 - ê±°ë¦¬)
            "full_question": doc.get("question"),
            "sql": doc.get("sql")
        }
        for doc, score in zip(results["metadatas"][0], results["distances"][0])
        if (1 - score) >= threshold  # âœ… ìœ ì‚¬ë„ ê¸°ì¤€ í•„í„°ë§ (0.7 ì´ìƒë§Œ ì¶œë ¥)
    ]

    # âœ… ê²€ìƒ‰ ê²°ê³¼ ì¶œë ¥
    if not filtered_results:
        print("âŒ ìœ ì‚¬í•œ ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        return {"vector_results": "âŒ ìœ ì‚¬í•œ ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤."}

    else:
        for i, res in enumerate(filtered_results):
            print(f"ğŸ” [{i+1}] ìœ ì‚¬ë„ ì ìˆ˜: {res['score']:.4f}")  # âœ… ë³€í™˜ëœ ìœ ì‚¬ë„ ì¶œë ¥
            print(f"ğŸ“Œ ì›ë³¸ ì§ˆë¬¸: {res['full_question']}")
            print(f"ğŸ“ ì—°ê´€ SQL: {res['sql']}\n")

    return {"vector_results": filtered_results}  # âœ… í•„í„°ë§ëœ ìœ ì‚¬ ì§ˆë¬¸ ë°˜í™˜


def extract_keywords_based_on_db(state: RealEstateState) -> RealEstateState:
    system_prompt = prompts['keyword_system_prompt']

    response = llm.invoke([
        SystemMessage(content=system_prompt),
        HumanMessage(content=state["messages"][-1].content)
    ])
    
    extracted_keywords = response.content.strip()
    result = json.loads(extracted_keywords)
    return {"keywordlist":result}

def generate_query(state: RealEstateState) -> RealEstateState:

    print("[generate_query] ì—´ì‹¬íˆ ë°ì´í„°ë² ì´ìŠ¤ ì¿¼ë¦¬ë¬¸ì„ ì‘ì„±ì¤‘ì…ë‹ˆë‹¤...")

    keywordlist = state['keywordlist']

    if keywordlist['Transaction Type'] == 'ë§¤ë§¤':
        prompt = prompts['base_prompt'] + prompts['sales_prompt']
        transaction_type = 'sales'
        
    else:
        prompt = prompts['base_prompt'] + prompts['rentals_prompt']
        transaction_type = 'rentals'
        
    table = db.get_table_info(table_names=[
        "addresses",
        transaction_type,
        "property_info",
        "property_locations",
        "location_distances",
        "cultural_facilities",
    ])

    prompt = prompt.format(
            table = table,
            top_k=5,
            user_query=state['messages'][-1].content
        )
    
    if state['vector_results'] != 'âŒ ìœ ì‚¬í•œ ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.':
        examples = "\n".join(
            [
                f"- **ì§ˆë¬¸:** {res['full_question']}\n  **SQL:** `{res['sql']}`"
                for res in state['vector_results']
            ]
        )
        prompt = prompt + f"\n\n**ìœ ì‚¬í•œ ì§ˆë¬¸ ì˜ˆì‹œ:**\n{examples}"
    
    response = llm.invoke([
            SystemMessage(content="ë‹¹ì‹ ì€ SQLite Database  ì¿¼ë¦¬ë¥¼ ìƒì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."),
            HumanMessage(prompt)
        ])
    
    print('[generate_query]: ì¿¼ë¦¬ë¬¸ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤!')
    
    return {"query_sql":response.content}

def clean_sql_response(state: RealEstateState) -> RealEstateState:
    print('[clean_sql_response]: ì¿¼ë¦¬ë¬¸ì„ ë‹¤ë“¬ëŠ” ì¤‘ ì…ë‹ˆë‹¤.')
    
    # 'query_sql' í‚¤ëŠ” í•­ìƒ ì¡´ì¬í•œë‹¤ê³  ê°€ì •
    query_sql = state['query_sql']

    # ì½”ë“œ ë¸”ë¡(````sql ... `````) ì œê±°
    if query_sql.startswith("```sql") and query_sql.endswith("```"):
        query_sql = query_sql[6:-3].strip()  # "```sql" ì œê±° í›„ ì•ë’¤ ê³µë°± ì œê±°

    # SQL ë¬¸ ëì— ì„¸ë¯¸ì½œë¡  ì¶”ê°€ (í•„ìš”ì‹œ)
    if not query_sql.strip().endswith(";"):
        query_sql = query_sql.strip() + ";"
        
    print('[clean_sql_response]: ì¿¼ë¦¬ë¬¸ ë‹¤ë“¬ê¸° ë.')
    # ìƒíƒœ ì—…ë°ì´íŠ¸
    return {"query_sql":query_sql}

def run_query(state: RealEstateState) -> RealEstateState:
    
    tool = QuerySQLDataBaseTool(db=db)
    results = tool._run(state["query_sql"])

    if results == '':
        results = 'ê²°ê³¼ì—†ìŒ'
        return {"results": results}

    return {"results":results}

def query_router(state: RealEstateState):
    # This is the router
    results = state["results"]
    if results == "ê²°ê³¼ì—†ìŒ":
        return "ê²°ê³¼ì—†ìŒ"
    else:
        return 'ê²°ê³¼ìˆìŒ'
    

def no_result_answer(state: RealEstateState) -> RealEstateState:
    query = state['messages'][-1].content

    no_result_answer_prompt = prompts['no_result_answer_prompt'].format(query=query)

    user_prompt = f"ì‚¬ìš©ì ì§ˆë¬¸:{query}"
    response = llm.invoke([
            SystemMessage(content=no_result_answer_prompt),
            HumanMessage(content=user_prompt)
        ])
    
    output = response.content.strip()

    return {'answers': output}


def clean_result_query(state: RealEstateState) -> RealEstateState:
    base_prompt = prompts['clean_result_base_prompt']

    keywordlist = state['keywordlist']

    if keywordlist['Transaction Type'] == 'ì „ì„¸' or keywordlist['Transaction Type'] == 'ì—†ìŒ':
        clean_result_query_prompt = base_prompt + prompts['clean_result_yearly_rental_prompt']
    
    elif keywordlist['Transaction Type'] == 'ì›”ì„¸':
        clean_result_query_prompt = base_prompt + prompts['clean_result_monthly_rental_prompt']
    
    else:
        clean_result_query_prompt = base_prompt + prompts['clean_result_sale_prompt']
        
    user_prompt=f"{state['results']}"

    response = llm.invoke([
            SystemMessage(content=clean_result_query_prompt),
            HumanMessage(content=user_prompt)
        ])
    
    output = response.content.strip()

    return {"clean_results":output}

# âœ… ì „ì—­ ë³€ìˆ˜ë¡œ ìµœì‹  properties ì €ì¥
latest_properties = []

def clean_response(state: RealEstateState) -> RealEstateState:
    global latest_properties
    print('[clean_response]: ì¿¼ë¦¬ë¬¸ì„ ë‹¤ë“¬ëŠ” ì¤‘ ì…ë‹ˆë‹¤.')

    clean_results = state['clean_results']

    # ```json ``` ì œê±°
    if clean_results.startswith("```json") and clean_results.endswith("```"):
        clean_results = clean_results[7:-3].strip()

    # None, NaN, Infinity ë³€í™˜
    clean_results = clean_results.replace("None", "null").replace("NaN", "0").replace("Infinity", "0")

    # ì—­ìŠ¬ë˜ì‹œ ì œê±°
    clean_results = re.sub(r'\\(?!["\\/bfnrtu])', '', clean_results)

    # í‚¤-ê°’ ìë™ ìˆ˜ì • (": "ê°€ ì—†ëŠ” ê²½ìš°)
    clean_results = re.sub(r"(\w+):", r'"\1":', clean_results)

    print(f"ğŸ’¡ JSON ë°ì´í„° í™•ì¸:\n{clean_results}")

    try:
        data_list = json.loads(clean_results)

        if not isinstance(data_list, list):
            print(f"âŒ JSON ë°ì´í„°ê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹˜: {type(data_list)}")
            raise ValueError("JSON ë°ì´í„°ê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹™ë‹ˆë‹¤.")

        latest_properties.clear()
        latest_properties.extend([
            {
                "property_id": item.get("property_id"),
                "latitude": item.get("latitude"),
                "longitude": item.get("longitude")
            }
            for item in data_list
        ])

        print(f"âœ… Updated properties: {latest_properties}")

        return {"properties": latest_properties}

    except json.JSONDecodeError as e:
        print(f"ğŸš¨ JSON íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"ğŸ’¡ JSON ë°ì´í„° í™•ì¸:\n{clean_results}")
        return {"properties": []}  # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜

def generate_response(state: RealEstateState)-> RealEstateState:
    print('[generate_response] ë‹µë³€ ìƒì„±ì¤‘ì…ë‹ˆë‹¤...')

    data = state['clean_results']
    keywordlist = state['keywordlist']

    if keywordlist['Transaction Type'] == 'ì „ì„¸' or keywordlist['Transaction Type'] == 'ì—†ìŒ':
        money_info = "**ğŸ’° ë³´ì¦ê¸ˆ:** [ë³´ì¦ê¸ˆ]"
    
    elif keywordlist['Transaction Type'] == 'ì›”ì„¸':
        money_info = "**ğŸ’° ë³´ì¦ê¸ˆ:** [ë³´ì¦ê¸ˆ]\n- **ğŸ’° ì›”ì„¸:** [ì›”ì„¸]"
    
    else:
        money_info = "**ğŸ’° ê°€ê²©:** [ê°€ê²©]"

    generate_response_prompt = prompts['generate_response_prompt'].format(money_info=money_info, data=data)

    user_prompt=f"""
    ì‚¬ìš©ìì˜ ì§ˆë¬¸: {state['messages'][-1].content}
    """
    response = llm.invoke([
            SystemMessage(content=generate_response_prompt),
            HumanMessage(content=user_prompt)
        ])
    
    output = response.content.strip()

    return {'answers': output}